{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39598f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b562652",
   "metadata": {},
   "source": [
    "# 1.  Write a python program to display all the header tags from wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c5387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4 #BeautifullSoup ver 4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18364dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://en.wikipedia.org/wiki/Main_Page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c380a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9029f784",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = soup.find_all(['h1','h2','h3','h4','h5','h6','h7'])\n",
    "print('List all the header tags :', *titles, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9996f3",
   "metadata": {},
   "source": [
    "# 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc03e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cd213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.imdb.com/chart/top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f923343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have all the tag in which there are the Movie Names.\n",
    "#Now we will extract the text from these tags one by one by looping over these tags\n",
    "\n",
    "name=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('td',class_='titleColumn'):\n",
    "    name.append(i.text)\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e9abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('td',class_='ratingColumn imdbRating'):\n",
    "    rate.append(i.text)\n",
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e6e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('span',class_='secondaryInfo'):\n",
    "    year.append(i.text)\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471381cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing lenght\n",
    "print(len(name),len(rate),len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e13d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Titles':name, 'Rating':rate,'Year':year})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feea7b6",
   "metadata": {},
   "source": [
    "# 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c5da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.imdb.com/india/top-rated-indian-movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1695e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have all the tag in which there are the Movie Names.\n",
    "#Now we will extract the text from these tags one by one by looping over these tags\n",
    "\n",
    "name=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('td',class_='titleColumn'):\n",
    "    name.append(i.text.replace('\\n',''))\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903fce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('td',class_='ratingColumn imdbRating'):\n",
    "    rate.append(i.text.replace('\\n',''))\n",
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a81f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('span',class_='secondaryInfo'):\n",
    "    year.append(i.text)\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6754b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing lenght\n",
    "print(len(name),len(rate),len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Titles':name, 'Rating':rate,'Year':year})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cdc977",
   "metadata": {},
   "source": [
    "# 4) Write a python program to scrape product name, price and discounts from https://meesho.com/bags\u0002ladies/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ce4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6994a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://meesho.com/bags-ladies/pl/p7vbp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d986b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have all the tag in which there are the Movie Names.\n",
    "#Now we will extract the text from these tags one by one by looping over these tags\n",
    "\n",
    "name=[] # empty list for store the\n",
    "\n",
    "\n",
    "for i in soup.find_all('p',class_='Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS'):\n",
    "    name.append(i.text.replace('\\n',''))\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f6d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "price=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('h5',class_='Text__StyledText-sc-oo0kvp-0 hiHdyy'):\n",
    "    price.append(i.text.replace('₹',''))\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b6e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('p',class_='Text__StyledText-sc-oo0kvp-0 fCJVtz NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm'):\n",
    "    disc.append(i.text)\n",
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing lenght\n",
    "print(len(name),len(price),len(disc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f20b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Titles':name, 'Pricing':price,'Discount':disc})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5dd6e0",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d67db",
   "metadata": {},
   "source": [
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8ed9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76373131",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbbe2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfce7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=[] # empty list for store the\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--pos'):\n",
    "    pos.append(int(i.text))\n",
    "    next\n",
    "for i in soup.find_all('td',class_='table-body__cell table-body__cell--position u-text-right'):\n",
    "    pos.append(int(i.text))\n",
    "pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470aefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "team=[] # empty list for store the\n",
    "for i in soup.find_all('span',class_ ='u-hide-phablet'):\n",
    "    if i.text=='':\n",
    "        break\n",
    "    else:\n",
    "        team.append(i.text)\n",
    "team\n",
    "#len(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heading--<span class=\"u-hide-mobile\">Matches</span>\n",
    "\n",
    "matches=[] # empty list for store the amtches\n",
    "points=[]   # empty list for store the points\n",
    "\n",
    "p=0\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--matches'):\n",
    "    matches.append(int(i.text))\n",
    "#next\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--points'):\n",
    "    points.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('td',class_='table-body__cell u-center-text'):\n",
    "    if p > 20:\n",
    "        print(matches[p])\n",
    "        exit\n",
    "    else:\n",
    "        if (p%2)==0:\n",
    "            matches.append(int(i.text))\n",
    "        else:\n",
    "            points.append(i.text)\n",
    "    p=p+1\n",
    "    \n",
    "\n",
    "print(matches)\n",
    "print(points)\n",
    "\n",
    "#i.find_all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06210f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[] # empty list for store the\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--rating u-text-right'):\n",
    "    rating.append(int(i.text.replace('\\n','')))\n",
    "    next\n",
    "for i in soup.find_all('td',class_='table-body__cell u-text-right rating'):\n",
    "    rating.append(i.text.replace('\\n',''))\n",
    "rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing lenght\n",
    "print(len(pos),len(team),len(matches),len(points),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdec098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'POSITION':pos,'TEAM':team,'MATCHES':matches, 'POINT':points,'RATING':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b38e9",
   "metadata": {},
   "source": [
    "# b) Top 10 ODI Batsmen along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9479b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=[] # empty list for store the\n",
    "for i in soup.find('span',class_='rankings-block__pos-number'):\n",
    "    pos.append(int(i.text.replace('\\n','')))\n",
    "    next\n",
    "p=1\n",
    "for i in soup.find_all('span',class_='rankings-table__pos-number'):\n",
    "\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        posstr=i.text.replace('\\n','')\n",
    "        posstr=posstr.replace('(0)','')\n",
    "        posint=int(posstr)\n",
    "        pos.append(int(posstr))\n",
    "    p=p+1\n",
    "\n",
    "pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "batsman=[] # empty list for store the\n",
    "\n",
    "for i in soup.find('div',class_='rankings-block__banner--name'):\n",
    "    batsman.append(i.text)\n",
    "p=1    \n",
    "for i in soup.find_all('td',class_='table-body__cell name'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        batsman.append(i.text.replace('\\n',''))\n",
    "    p=p+1\n",
    "batsman\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2834e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "team=[] # empty list for store the\n",
    "\n",
    "team.append('PAK')\n",
    "\n",
    "p=1\n",
    "for i in soup.find_all('span',class_ ='table-body__logo-text'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        team.append(i.text)\n",
    "    p=p+1\n",
    "    \n",
    "    \n",
    "team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb1d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RATING\n",
    "rating=[] \n",
    "for i in soup.find('div',class_='rankings-block__banner--rating'):\n",
    "    rating.append(int(i.text.replace('\\n','')))\n",
    "\n",
    "p=1\n",
    "for i in soup.find_all('td',class_='table-body__cell u-text-right rating'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        rating.append(i.text.replace('\\n',''))\n",
    "    p=p+1    \n",
    "rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81230077",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pos),len(batsman),len(team),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa561a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'POSITION':pos,'BATSMAN':batsman,'TEAM':team,'RATING':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c18d92",
   "metadata": {},
   "source": [
    "# c) Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3edbe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51a4d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427d144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136757c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=[] # empty list for store the\n",
    "for i in soup.find('span',class_='rankings-block__pos-number'):\n",
    "    pos.append(int(i.text.replace('\\n','')))\n",
    "    next\n",
    "p=1\n",
    "for i in soup.find_all('span',class_='rankings-table__pos-number'):\n",
    "\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        posstr=i.text.replace('\\n','')\n",
    "        posstr=posstr.replace('(0)','')\n",
    "        posint=int(posstr)\n",
    "        pos.append(int(posstr))\n",
    "    p=p+1\n",
    "\n",
    "pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963cd794",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowler=[] # empty list for store the\n",
    "\n",
    "for i in soup.find('div',class_='rankings-block__banner--name-large'):\n",
    "    #print(i.text)\n",
    "    bowler.append(i.text)\n",
    "p=1    \n",
    "for i in soup.find_all('td',class_='table-body__cell rankings-table__name name'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        bowler.append(i.text.replace('\\n',''))\n",
    "    p=p+1\n",
    "bowler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "team=[] # empty list for store the\n",
    "\n",
    "team.append('NZ')\n",
    "p=1\n",
    "for i in soup.find_all('span',class_ ='table-body__logo-text'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        team.append(i.text)\n",
    "    p=p+1\n",
    "    \n",
    "    \n",
    "team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6236230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RATING\n",
    "rating=[] \n",
    "for i in soup.find('div',class_='rankings-block__banner--rating'):\n",
    "    rating.append(int(i.text.replace('\\n','')))\n",
    "\n",
    "p=1\n",
    "for i in soup.find_all('td',class_='table-body__cell rating'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        rating.append(i.text.replace('\\n',''))\n",
    "    p=p+1    \n",
    "rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18263f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pos),len(bowler),len(team),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ca789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'POSITION':pos,'BOWLER':bowler,'TEAM':team,'RATING':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9864218a",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d7742c",
   "metadata": {},
   "source": [
    "# a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42bb557",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96faa04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3bfedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=[] # empty list for store the\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--pos'):\n",
    "    pos.append(int(i.text))\n",
    "    next\n",
    "for i in soup.find_all('td',class_='table-body__cell table-body__cell--position u-text-right'):\n",
    "    pos.append(int(i.text))\n",
    "pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dfa7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "team=[] # empty list for store the\n",
    "for i in soup.find_all('span',class_ ='u-hide-phablet'):\n",
    "    if i.text=='':\n",
    "        break\n",
    "    else:\n",
    "        team.append(i.text)\n",
    "team\n",
    "#len(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches=[] \n",
    "points=[]  \n",
    "\n",
    "p=0\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--matches'):\n",
    "    matches.append(int(i.text))\n",
    "\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--points'):\n",
    "    points.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('td',class_='table-body__cell u-center-text'):\n",
    "    if p > 20:\n",
    "        print(matches[p])\n",
    "        exit\n",
    "    else:\n",
    "        if (p%2)==0:\n",
    "            matches.append(int(i.text))\n",
    "        else:\n",
    "            points.append(i.text)\n",
    "    p=p+1\n",
    "\n",
    "print(matches)\n",
    "print(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f98fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[] # empty list for store the\n",
    "for i in soup.find_all('td',class_='rankings-block__banner--rating u-text-right'):\n",
    "    rating.append(int(i.text.replace('\\n','')))\n",
    "    next\n",
    "for i in soup.find_all('td',class_='table-body__cell u-text-right rating'):\n",
    "    rating.append(i.text.replace('\\n',''))\n",
    "rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d35519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing lenght\n",
    "print(len(pos),len(team),len(matches),len(points),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e286e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'POSITION':pos,'TEAM':team,'MATCHES':matches, 'POINT':points,'RATING':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c2c00",
   "metadata": {},
   "source": [
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd812a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08994377",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83039ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=[] # empty list for store the\n",
    "for i in soup.find('span',class_='rankings-block__pos-number'):\n",
    "    pos.append(int(i.text.replace('\\n','')))\n",
    "    next\n",
    "p=1\n",
    "for i in soup.find_all('span',class_='rankings-table__pos-number'):\n",
    "\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        posstr=i.text.replace('\\n','')\n",
    "        posstr=posstr.replace('(0)','')\n",
    "        posint=int(posstr)\n",
    "        pos.append(int(posstr))\n",
    "    p=p+1\n",
    "\n",
    "print(pos)\n",
    "\n",
    "\n",
    "batsman=[] # empty list for store the\n",
    "\n",
    "for i in soup.find('div',class_='rankings-block__banner--name-large'):\n",
    "    batsman.append(i.text)\n",
    "p=1    \n",
    "for i in soup.find_all('td',class_='table-body__cell rankings-table__name name'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        batsman.append(i.text.replace('\\n',''))\n",
    "    p=p+1\n",
    "print(batsman)\n",
    "\n",
    "\n",
    "team=[] # empty list for store the\n",
    "team.append('AUS')\n",
    "\n",
    "p=1\n",
    "for i in soup.find_all('span',class_ ='table-body__logo-text'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        team.append(i.text)\n",
    "    p=p+1\n",
    "print(team)\n",
    "\n",
    "\n",
    "#RATING\n",
    "rating=[] \n",
    "for i in soup.find('div',class_='rankings-block__banner--rating'):\n",
    "    rating.append(int(i.text.replace('\\n','')))\n",
    "\n",
    "p=1\n",
    "for i in soup.find_all('td',class_='table-body__cell rating'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        rating.append(i.text.replace('\\n',''))\n",
    "    p=p+1    \n",
    "print(rating)\n",
    "\n",
    "\n",
    "print(len(pos),len(batsman),len(team),len(rating))\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'POSITION':pos,'BATSMAN':batsman,'TEAM':team,'RATING':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc5b31",
   "metadata": {},
   "source": [
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c39a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=[] # empty list for store the\n",
    "for i in soup.find('span',class_='rankings-block__pos-number'):\n",
    "    pos.append(int(i.text.replace('\\n','')))\n",
    "    next\n",
    "p=1\n",
    "for i in soup.find_all('span',class_='rankings-table__pos-number'):\n",
    "\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        posstr=i.text.replace('\\n','')\n",
    "        posstr=posstr.replace('(0)','')\n",
    "        posint=int(posstr)\n",
    "        pos.append(int(posstr))\n",
    "    p=p+1\n",
    "\n",
    "print(pos)\n",
    "#____________________________________________\n",
    "\n",
    "allrounder=[] # empty list for store the\n",
    "\n",
    "for i in soup.find('div',class_='rankings-block__banner--name-large'):\n",
    "    #print(i.text)\n",
    "    allrounder.append(i.text)\n",
    "p=1    \n",
    "for i in soup.find_all('td',class_='table-body__cell rankings-table__name name'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        allrounder.append(i.text.replace('\\n',''))\n",
    "    p=p+1\n",
    "print(allrounder)\n",
    "\n",
    "#---------------------------------------------\n",
    "team=[] # empty list for store the\n",
    "team.append('AUS')\n",
    "\n",
    "p=1\n",
    "for i in soup.find_all('span',class_ ='table-body__logo-text'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        team.append(i.text)\n",
    "    p=p+1\n",
    "print(team)\n",
    "#--------------------------------------------\n",
    "\n",
    "#RATING\n",
    "rating=[] \n",
    "for i in soup.find('div',class_='rankings-block__banner--rating'):\n",
    "    rating.append(int(i.text.replace('\\n','')))\n",
    "\n",
    "p=1\n",
    "for i in soup.find_all('td',class_='table-body__cell rating'):\n",
    "    if p > 9:\n",
    "        exit\n",
    "    else:\n",
    "        rating.append(i.text.replace('\\n',''))\n",
    "    p=p+1    \n",
    "print(rating)\n",
    "#___________________________________________________________________\n",
    "\n",
    "print(len(pos),len(allrounder),len(team),len(rating))\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'POSITION':pos,'ALLROUNDER':allrounder,'TEAM':team,'RATING':rating})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aeab0c",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content and the code for the video from the link for the youtube video from the post.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get('https://coreyms.com/')\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ca2c857",
   "metadata": {},
   "source": [
    "HEADING, DATE, CONTENT, CODE FOR THE VIDEO\n",
    "#heading---h2, 'entry-title',\n",
    "#Date--time,'entry-time'\n",
    "#Content---div,'entry-content'\n",
    "#link---a,'ytp-title-link yt-uix-sessionlink'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01831690",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('a',class_='entry-title-link'):\n",
    "    heading.append(i.text)\n",
    "print(heading)\n",
    "len(heading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ee3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('time',class_='entry-time'):\n",
    "    date.append(i.text)\n",
    "print(date)\n",
    "len(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4517919",
   "metadata": {},
   "outputs": [],
   "source": [
    "content=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('div',class_='entry-content'):\n",
    "    content.append(i.text)\n",
    "print(content)\n",
    "len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1308312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "link=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('span',class_='embed-youtube'):\n",
    "    link.append(i.text)\n",
    "print(link)\n",
    "len(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec18307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing lengh\n",
    "print(len(heading),len(date),len(content),len(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e585d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'HEADING':heading,'DATE':date, 'CONTENT':content})#'LINK':link \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd05313",
   "metadata": {},
   "source": [
    "# 8) Write a python program to scrape house details from mentioned URL. It should include house title, location,area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar, Rajaji Nagar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6507e10e",
   "metadata": {},
   "source": [
    "# location--Indira Nagar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6dc245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get('https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45MzA3NzM1LCJsb24iOjc3LjU4MzgzMDIsInBsYWNlSWQiOiJDaElKMmRkbFo1Z1ZyanNSaDFCT0FhZi1vcnMiLCJwbGFjZU5hbWUiOiJKYXlhbmFnYXIifSx7ImxhdCI6MTIuOTc4MzY5MiwibG9uIjo3Ny42NDA4MzU2LCJwbGFjZUlkIjoiQ2hJSmtRTjNHS1FXcmpzUk5oQlFKcmhHRDdVIiwicGxhY2VOYW1lIjoiSW5kaXJhbmFnYXIifSx7ImxhdCI6MTIuOTk4MTczMiwibG9uIjo3Ny41NTMwNDQ1OTk5OTk5OSwicGxhY2VJZCI6IkNoSUp4Zlc0RFBNOXJqc1JLc05URy01cF9RUSIsInBsYWNlTmFtZSI6IlJhamFqaW5hZ2FyIn1d&radius=2.0&city=bangalore&locality[0]=Indiranagar,&locality[1]=Jayanagar,&locality[2]=Rajajinagar')\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf3bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "housetitle=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('span', class_=\"overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full\"):\n",
    "    housetitle.append(i.text)\n",
    "housetitle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b654992",
   "metadata": {},
   "outputs": [],
   "source": [
    "AreaEMIPrice=[]\n",
    "for i in soup.find_all('div',class_='font-semi-bold heading-6'):\n",
    "    AreaEMIPrice.append(i.text)\n",
    "#print(AreaEMIPrice)\n",
    "\n",
    "Area=[]\n",
    "EMI=[]\n",
    "Price=[]\n",
    "i=0\n",
    "while i<len(AreaEMIPrice):\n",
    "    Area.append(AreaEMIPrice[i])\n",
    "    i=i+1\n",
    "    EMI.append(AreaEMIPrice[i])\n",
    "    i=i+1\n",
    "    Price.append(AreaEMIPrice[i])\n",
    "    i=i+1\n",
    "\n",
    "print(Area)\n",
    "print(EMI)\n",
    "print(Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad4795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(housetitle),len(Area),len(EMI),len(Price))\n",
    "\n",
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'HEADING':housetitle,'Area':Area,'EMI':EMI,'PRice':Price}) #,'LINK':link\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae101b0",
   "metadata": {},
   "source": [
    "# 9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get('https://www.dineout.co.in/goa-restaurants/seafood-cuisine?city_name=goa&limit=21&start=0&cityId=8&listing=1&showAvailableTicket=0&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood&cuisine%5B%5D=Seafood')\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bac458",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Restaurantname=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('a', class_=\"restnt-name ellipsis\"):\n",
    "    Restaurantname.append(i.text)\n",
    "print(Restaurantname)\n",
    "len(Restaurantname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cuisine=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('span', class_=\"double-line-ellipsis\"):\n",
    "    b=i.text\n",
    "    b=b.split(\"|\")\n",
    "    Cuisine.append(b[1])\n",
    "print(Cuisine)\n",
    "len(Cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d827071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Location=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('div', class_=\"restnt-loc ellipsis\"):\n",
    "    Location.append(i.text)\n",
    "print(Location)\n",
    "len(Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d0a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings=[] # empty list for store the\n",
    "\n",
    "'''for i in soup.find_all('div', class_=\"restnt-rating rating-4\"):\n",
    "    Ratings.append(i.text)\n",
    "for i in soup.find_all('div', class_=\"restnt-rating rating-5\"):\n",
    "    Ratings.append(i.text)\n",
    "for i in soup.find_all('div', class_=\"restnt-rating rating-3\"):\n",
    "    Ratings.append(i.text)'''\n",
    "for i in soup.find_all('div', class_=\"img-wrap\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "print(Ratings)\n",
    "len(Ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a991f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageURL=[] # empty list for store the\n",
    "\n",
    "for i in soup.find_all('div', class_=\"img cursor\"):\n",
    "    ImageURL.append(i.text)\n",
    "print(ImageURL)\n",
    "len(ImageURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(Restaurantname),len(Cuisine),len(Location),len(Ratings),len(ImageURL))\n",
    "\n",
    "#Making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Restaurantname':Restaurantname,'Cuisine':Cuisine,'Location':Location,'Ratings':Ratings,'ImageURL':ImageURL}) #,'LINK':link\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a95f5e7",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape first 10 product details which include product name , price , Image URL from https://www.bewakoof.com/women-tshirts?ga_q=tshirts ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get('https://www.bewakoof.com/women-clothing/category-t-shirt')\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc6b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ae8b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276bc08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "productname=[]\n",
    "for i in soup.find_all('div', class_=\"productCardDetail\",limit=10):\n",
    "    b=i.text\n",
    "    b=b.split(\"₹\")\n",
    "    productname.append(b[0])\n",
    "print(productname,\"\\n\")\n",
    "len(productname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9e9b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "price=[]\n",
    "for i in soup.find_all('div', class_=\"productCardDetail\",limit=10):\n",
    "    b=i.text\n",
    "    b=b.split(\"₹\")\n",
    "    b=re.findall(r'\\d+',b[2])\n",
    "    print(b)\n",
    "    price.append(b)\n",
    "print(price)\n",
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7accc251",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageURL=[]\n",
    "for i in soup.find_all('div', class_=\"productImg\"):\n",
    "    ImageURL.append(i.text)\n",
    "print(ImageURL)\n",
    "len(ImageURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(productname),len(price),len(ImageURL))\n",
    "\n",
    "#Making dataframe\n",
    "import pandas as pd\n",
    "      \n",
    "df=pd.DataFrame({'Product Name':productname,'Price':price,'ImageURL':ImageURL})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf6138",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
